{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjKRSsWb9s3p"
   },
   "source": [
    "# Ciência de Dados na Saúde: Criando Modelos para Predição do Câncer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJBH-Hwjcrah"
   },
   "source": [
    "## # Case: Classificação de Câncer por meio de microRNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4H73tAiIeHoY"
   },
   "source": [
    "**Descrição dos Dados:** Os dados foram coletados do [The Cancer Genome Atlas](https://www.cancer.gov/ccg/research/genome-sequencing/tcga) (TCGA), que é um programa internacional e de referência mundial de caracterização de mais de 33 tipos de câncer. Os dados são reais e foram devidamente anonimizados. Cada linha representa a amostra retirada de uma pessoa. As colunas são os tipos de microRNA e cada entrada representa a intensidade com que aquele microRNA está expresso. Os valores de expressão variam entre $[0, \\infty]$. Valores próximos a zero indicam pouca expressão enquanto que o contrário indica uma alta expressão. Os dados também apresentam rótulos (veja o atributo class) sendo TP (primary solid tumor) indicando tumor e NT (normal tissue).\n",
    "\n",
    "\n",
    "**Objetivo:** Construir um modelo para predizer quando uma pessoa tem câncer dado um exame de sequenciamento do RNA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_BWys_jdE_v"
   },
   "source": [
    "## Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "m0fJuzemhi7t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K2aH2mRabjRz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa.let.7a.1</th>\n",
       "      <th>hsa.let.7a.2</th>\n",
       "      <th>hsa.let.7a.3</th>\n",
       "      <th>hsa.let.7b</th>\n",
       "      <th>hsa.let.7c</th>\n",
       "      <th>hsa.let.7d</th>\n",
       "      <th>hsa.let.7e</th>\n",
       "      <th>hsa.let.7f.1</th>\n",
       "      <th>hsa.let.7f.2</th>\n",
       "      <th>hsa.let.7g</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa.mir.941.1</th>\n",
       "      <th>hsa.mir.942</th>\n",
       "      <th>hsa.mir.943</th>\n",
       "      <th>hsa.mir.944</th>\n",
       "      <th>hsa.mir.95</th>\n",
       "      <th>hsa.mir.96</th>\n",
       "      <th>hsa.mir.98</th>\n",
       "      <th>hsa.mir.99a</th>\n",
       "      <th>hsa.mir.99b</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8962.996542</td>\n",
       "      <td>17779.575039</td>\n",
       "      <td>9075.200383</td>\n",
       "      <td>24749.898857</td>\n",
       "      <td>341.298400</td>\n",
       "      <td>406.164781</td>\n",
       "      <td>1470.179650</td>\n",
       "      <td>14.716795</td>\n",
       "      <td>3627.642977</td>\n",
       "      <td>387.417272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.530515</td>\n",
       "      <td>0.187475</td>\n",
       "      <td>2.062226</td>\n",
       "      <td>4.124452</td>\n",
       "      <td>119.984057</td>\n",
       "      <td>53.992826</td>\n",
       "      <td>130.201449</td>\n",
       "      <td>46548.939810</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7739.739862</td>\n",
       "      <td>15524.941906</td>\n",
       "      <td>7713.626636</td>\n",
       "      <td>23374.640471</td>\n",
       "      <td>801.487258</td>\n",
       "      <td>513.297924</td>\n",
       "      <td>560.962427</td>\n",
       "      <td>20.922042</td>\n",
       "      <td>6557.093894</td>\n",
       "      <td>350.955461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.180047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629234</td>\n",
       "      <td>1.258469</td>\n",
       "      <td>60.249189</td>\n",
       "      <td>86.047798</td>\n",
       "      <td>236.434808</td>\n",
       "      <td>12644.149725</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8260.612670</td>\n",
       "      <td>16497.981335</td>\n",
       "      <td>8355.342958</td>\n",
       "      <td>10957.355911</td>\n",
       "      <td>635.811272</td>\n",
       "      <td>620.351816</td>\n",
       "      <td>2694.331127</td>\n",
       "      <td>39.799878</td>\n",
       "      <td>11830.760394</td>\n",
       "      <td>600.725980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.618171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767491</td>\n",
       "      <td>1.644623</td>\n",
       "      <td>97.252043</td>\n",
       "      <td>117.645369</td>\n",
       "      <td>191.434123</td>\n",
       "      <td>33083.456616</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9056.241254</td>\n",
       "      <td>18075.168478</td>\n",
       "      <td>9097.666150</td>\n",
       "      <td>26017.522731</td>\n",
       "      <td>2919.348415</td>\n",
       "      <td>334.245155</td>\n",
       "      <td>1322.434475</td>\n",
       "      <td>17.866463</td>\n",
       "      <td>6438.725384</td>\n",
       "      <td>354.957604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.478426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.478426</td>\n",
       "      <td>1.739213</td>\n",
       "      <td>72.572624</td>\n",
       "      <td>41.583007</td>\n",
       "      <td>1046.690127</td>\n",
       "      <td>24067.232290</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10897.303665</td>\n",
       "      <td>21822.338727</td>\n",
       "      <td>10963.956320</td>\n",
       "      <td>22204.253575</td>\n",
       "      <td>3313.009950</td>\n",
       "      <td>350.615669</td>\n",
       "      <td>1711.886682</td>\n",
       "      <td>22.541895</td>\n",
       "      <td>8246.117280</td>\n",
       "      <td>333.425447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.108235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.135203</td>\n",
       "      <td>0.810860</td>\n",
       "      <td>19.947145</td>\n",
       "      <td>34.380445</td>\n",
       "      <td>1081.037952</td>\n",
       "      <td>25715.275426</td>\n",
       "      <td>TP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 898 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hsa.let.7a.1  hsa.let.7a.2  hsa.let.7a.3    hsa.let.7b   hsa.let.7c  \\\n",
       "0   8962.996542  17779.575039   9075.200383  24749.898857   341.298400   \n",
       "1   7739.739862  15524.941906   7713.626636  23374.640471   801.487258   \n",
       "2   8260.612670  16497.981335   8355.342958  10957.355911   635.811272   \n",
       "3   9056.241254  18075.168478   9097.666150  26017.522731  2919.348415   \n",
       "4  10897.303665  21822.338727  10963.956320  22204.253575  3313.009950   \n",
       "\n",
       "   hsa.let.7d   hsa.let.7e  hsa.let.7f.1  hsa.let.7f.2  hsa.let.7g  ...  \\\n",
       "0  406.164781  1470.179650     14.716795   3627.642977  387.417272  ...   \n",
       "1  513.297924   560.962427     20.922042   6557.093894  350.955461  ...   \n",
       "2  620.351816  2694.331127     39.799878  11830.760394  600.725980  ...   \n",
       "3  334.245155  1322.434475     17.866463   6438.725384  354.957604  ...   \n",
       "4  350.615669  1711.886682     22.541895   8246.117280  333.425447  ...   \n",
       "\n",
       "   hsa.mir.941.1  hsa.mir.942  hsa.mir.943  hsa.mir.944  hsa.mir.95  \\\n",
       "0            0.0     5.530515     0.187475     2.062226    4.124452   \n",
       "1            0.0     8.180047     0.000000     0.629234    1.258469   \n",
       "2            0.0     3.618171     0.000000     0.767491    1.644623   \n",
       "3            0.0     3.478426     0.000000     3.478426    1.739213   \n",
       "4            0.0     2.108235     0.000000     1.135203    0.810860   \n",
       "\n",
       "   hsa.mir.96  hsa.mir.98  hsa.mir.99a   hsa.mir.99b  class  \n",
       "0  119.984057   53.992826   130.201449  46548.939810     TP  \n",
       "1   60.249189   86.047798   236.434808  12644.149725     TP  \n",
       "2   97.252043  117.645369   191.434123  33083.456616     TP  \n",
       "3   72.572624   41.583007  1046.690127  24067.232290     TP  \n",
       "4   19.947145   34.380445  1081.037952  25715.275426     TP  \n",
       "\n",
       "[5 rows x 898 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando o arquivo e o atribuindo a um objeto df\n",
    "df = pd.read_csv(\"brca_mirnaseq.csv\", decimal=\",\", sep=\";\", header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ki3_luTFmQDn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(842, 898)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando quantidade de indivíduos e features (892 indivíduos, 898 features)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-3MzuzpdXPG"
   },
   "source": [
    "## Análise Exploratória dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zasmZRzyddbq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checando balanceamento entre os dados\n",
    "ax = sns.countplot(x=\"class\", data=df, hue=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AGqvfRIgmPJG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "TP    755\n",
       "NT     87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando a quantidade exata de cada classe \n",
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MudP9wyJnMiX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "TP    89.667458\n",
       "NT    10.332542\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checando a proporção entre as classes\n",
    "df[\"class\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BFObjpRUpLG7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa.let.7a.1</th>\n",
       "      <th>hsa.let.7a.2</th>\n",
       "      <th>hsa.let.7a.3</th>\n",
       "      <th>hsa.let.7b</th>\n",
       "      <th>hsa.let.7c</th>\n",
       "      <th>hsa.let.7d</th>\n",
       "      <th>hsa.let.7e</th>\n",
       "      <th>hsa.let.7f.1</th>\n",
       "      <th>hsa.let.7f.2</th>\n",
       "      <th>hsa.let.7g</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa.mir.940</th>\n",
       "      <th>hsa.mir.941.1</th>\n",
       "      <th>hsa.mir.942</th>\n",
       "      <th>hsa.mir.943</th>\n",
       "      <th>hsa.mir.944</th>\n",
       "      <th>hsa.mir.95</th>\n",
       "      <th>hsa.mir.96</th>\n",
       "      <th>hsa.mir.98</th>\n",
       "      <th>hsa.mir.99a</th>\n",
       "      <th>hsa.mir.99b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "      <td>842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9218.938921</td>\n",
       "      <td>18432.504585</td>\n",
       "      <td>9289.250466</td>\n",
       "      <td>26606.604836</td>\n",
       "      <td>3152.699471</td>\n",
       "      <td>558.321269</td>\n",
       "      <td>1289.570177</td>\n",
       "      <td>24.359962</td>\n",
       "      <td>8687.461926</td>\n",
       "      <td>610.223836</td>\n",
       "      <td>...</td>\n",
       "      <td>5.902975</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>6.446279</td>\n",
       "      <td>0.061018</td>\n",
       "      <td>2.320737</td>\n",
       "      <td>3.150482</td>\n",
       "      <td>38.307053</td>\n",
       "      <td>63.746405</td>\n",
       "      <td>1034.572148</td>\n",
       "      <td>44369.112203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4843.796136</td>\n",
       "      <td>9704.187427</td>\n",
       "      <td>4858.691217</td>\n",
       "      <td>16745.347957</td>\n",
       "      <td>3238.003201</td>\n",
       "      <td>346.883205</td>\n",
       "      <td>763.056055</td>\n",
       "      <td>12.490091</td>\n",
       "      <td>6052.615278</td>\n",
       "      <td>317.854963</td>\n",
       "      <td>...</td>\n",
       "      <td>8.325681</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>9.541682</td>\n",
       "      <td>0.172214</td>\n",
       "      <td>6.527536</td>\n",
       "      <td>4.287594</td>\n",
       "      <td>33.791795</td>\n",
       "      <td>40.145314</td>\n",
       "      <td>1117.491608</td>\n",
       "      <td>32754.290751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1294.149164</td>\n",
       "      <td>2599.981125</td>\n",
       "      <td>1319.952907</td>\n",
       "      <td>1817.920354</td>\n",
       "      <td>148.795934</td>\n",
       "      <td>79.783216</td>\n",
       "      <td>161.181457</td>\n",
       "      <td>2.439034</td>\n",
       "      <td>653.474578</td>\n",
       "      <td>88.614573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.374223</td>\n",
       "      <td>18.400719</td>\n",
       "      <td>3475.079227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5902.143848</td>\n",
       "      <td>11741.467528</td>\n",
       "      <td>5933.706564</td>\n",
       "      <td>14580.357100</td>\n",
       "      <td>1276.700850</td>\n",
       "      <td>330.638301</td>\n",
       "      <td>809.867504</td>\n",
       "      <td>16.441786</td>\n",
       "      <td>4648.822942</td>\n",
       "      <td>410.859815</td>\n",
       "      <td>...</td>\n",
       "      <td>1.378098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.464140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373238</td>\n",
       "      <td>1.201951</td>\n",
       "      <td>14.906921</td>\n",
       "      <td>39.913493</td>\n",
       "      <td>387.430475</td>\n",
       "      <td>22769.094433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8016.628565</td>\n",
       "      <td>16040.589880</td>\n",
       "      <td>8103.783439</td>\n",
       "      <td>23097.825936</td>\n",
       "      <td>2352.902327</td>\n",
       "      <td>481.342371</td>\n",
       "      <td>1101.403395</td>\n",
       "      <td>21.890340</td>\n",
       "      <td>7019.157941</td>\n",
       "      <td>532.277053</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.127957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.036215</td>\n",
       "      <td>2.235731</td>\n",
       "      <td>29.634884</td>\n",
       "      <td>52.993693</td>\n",
       "      <td>710.026124</td>\n",
       "      <td>35594.670263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11236.887034</td>\n",
       "      <td>22538.594950</td>\n",
       "      <td>11289.595988</td>\n",
       "      <td>34373.185504</td>\n",
       "      <td>3971.192192</td>\n",
       "      <td>681.931022</td>\n",
       "      <td>1619.864372</td>\n",
       "      <td>29.395515</td>\n",
       "      <td>10926.448322</td>\n",
       "      <td>724.277709</td>\n",
       "      <td>...</td>\n",
       "      <td>7.159431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.551755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.345941</td>\n",
       "      <td>4.030888</td>\n",
       "      <td>51.258145</td>\n",
       "      <td>75.993914</td>\n",
       "      <td>1242.434228</td>\n",
       "      <td>53462.034662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45101.697434</td>\n",
       "      <td>90233.655610</td>\n",
       "      <td>45095.490102</td>\n",
       "      <td>144706.427973</td>\n",
       "      <td>59677.212349</td>\n",
       "      <td>3370.036117</td>\n",
       "      <td>11617.011618</td>\n",
       "      <td>121.408006</td>\n",
       "      <td>80780.055188</td>\n",
       "      <td>3342.745045</td>\n",
       "      <td>...</td>\n",
       "      <td>91.996543</td>\n",
       "      <td>0.909391</td>\n",
       "      <td>184.185656</td>\n",
       "      <td>1.757516</td>\n",
       "      <td>122.685820</td>\n",
       "      <td>93.402785</td>\n",
       "      <td>259.127121</td>\n",
       "      <td>399.078716</td>\n",
       "      <td>15689.499524</td>\n",
       "      <td>248074.178531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 897 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hsa.let.7a.1  hsa.let.7a.2  hsa.let.7a.3     hsa.let.7b    hsa.let.7c  \\\n",
       "count    842.000000    842.000000    842.000000     842.000000    842.000000   \n",
       "mean    9218.938921  18432.504585   9289.250466   26606.604836   3152.699471   \n",
       "std     4843.796136   9704.187427   4858.691217   16745.347957   3238.003201   \n",
       "min     1294.149164   2599.981125   1319.952907    1817.920354    148.795934   \n",
       "25%     5902.143848  11741.467528   5933.706564   14580.357100   1276.700850   \n",
       "50%     8016.628565  16040.589880   8103.783439   23097.825936   2352.902327   \n",
       "75%    11236.887034  22538.594950  11289.595988   34373.185504   3971.192192   \n",
       "max    45101.697434  90233.655610  45095.490102  144706.427973  59677.212349   \n",
       "\n",
       "        hsa.let.7d    hsa.let.7e  hsa.let.7f.1  hsa.let.7f.2   hsa.let.7g  \\\n",
       "count   842.000000    842.000000    842.000000    842.000000   842.000000   \n",
       "mean    558.321269   1289.570177     24.359962   8687.461926   610.223836   \n",
       "std     346.883205    763.056055     12.490091   6052.615278   317.854963   \n",
       "min      79.783216    161.181457      2.439034    653.474578    88.614573   \n",
       "25%     330.638301    809.867504     16.441786   4648.822942   410.859815   \n",
       "50%     481.342371   1101.403395     21.890340   7019.157941   532.277053   \n",
       "75%     681.931022   1619.864372     29.395515  10926.448322   724.277709   \n",
       "max    3370.036117  11617.011618    121.408006  80780.055188  3342.745045   \n",
       "\n",
       "       ...  hsa.mir.940  hsa.mir.941.1  hsa.mir.942  hsa.mir.943  hsa.mir.944  \\\n",
       "count  ...   842.000000     842.000000   842.000000   842.000000   842.000000   \n",
       "mean   ...     5.902975       0.003737     6.446279     0.061018     2.320737   \n",
       "std    ...     8.325681       0.049274     9.541682     0.172214     6.527536   \n",
       "min    ...     0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%    ...     1.378098       0.000000     2.464140     0.000000     0.373238   \n",
       "50%    ...     3.192098       0.000000     4.127957     0.000000     1.036215   \n",
       "75%    ...     7.159431       0.000000     7.551755     0.000000     2.345941   \n",
       "max    ...    91.996543       0.909391   184.185656     1.757516   122.685820   \n",
       "\n",
       "       hsa.mir.95  hsa.mir.96  hsa.mir.98   hsa.mir.99a    hsa.mir.99b  \n",
       "count  842.000000  842.000000  842.000000    842.000000     842.000000  \n",
       "mean     3.150482   38.307053   63.746405   1034.572148   44369.112203  \n",
       "std      4.287594   33.791795   40.145314   1117.491608   32754.290751  \n",
       "min      0.000000    0.000000    3.374223     18.400719    3475.079227  \n",
       "25%      1.201951   14.906921   39.913493    387.430475   22769.094433  \n",
       "50%      2.235731   29.634884   52.993693    710.026124   35594.670263  \n",
       "75%      4.030888   51.258145   75.993914   1242.434228   53462.034662  \n",
       "max     93.402785  259.127121  399.078716  15689.499524  248074.178531  \n",
       "\n",
       "[8 rows x 897 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explorando a distribuição geral dos dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Dn-9490do7Q"
   },
   "source": [
    "## Estabelecendo um Baseline Comparativo\n",
    "\n",
    "Antes de qualquer modelagem, vamos estabelecer um baseline, i.e., uma solução simples para o problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PYnwDvX_xUOO"
   },
   "outputs": [],
   "source": [
    "# Separando a feature que eu quero prever (variável dependente) em outro dataframe(y) e as features independentes no dataframe X de forma estratificada em 30%/70%\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QrAMmLCJx8xS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "TP    89.643463\n",
       "NT    10.356537\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se a estratificação foi feita corretamente entre o y de treino\n",
    "y_train.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D9-BJRzdyIXA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "TP    89.72332\n",
       "NT    10.27668\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando se a estratificação foi feita corretamente entre o y de teste\n",
    "y_test.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\renat\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrc = LogisticRegression(random_state=42)\n",
    "cv_list_lr_baseline = cross_val_score (\n",
    "    lrc,\n",
    "    X_train,\n",
    "    y_train, \n",
    "    cv=10,\n",
    "    scoring=\"balanced_accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance (bac): 0.9201 +- 0.046\n"
     ]
    }
   ],
   "source": [
    "#Verificando a acurácia balanceada (bac) e desvio-padrão\n",
    "mean_cv_lr_baseline = np.mean(cv_list_lr_baseline)\n",
    "std_cv_lr_baseline = np.std(cv_list_lr_baseline)\n",
    "print(f\"Performance (bac): {round(mean_cv_lr_baseline,4)} +- {round(std_cv_lr_baseline,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xL43SL9wdx4p"
   },
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OjhBAMI-0af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance (bac): 0.9703 +- 0.0377\n"
     ]
    }
   ],
   "source": [
    "knn = Pipeline (\n",
    "    [\n",
    "        (\"mms\", MinMaxScaler()),\n",
    "        (\"skb\", SelectKBest(chi2, k=10)),\n",
    "        (\"knn\", KNeighborsClassifier(n_neighbors=3, p=2,weights=\"uniform\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_list_knn_euclid = cross_val_score (\n",
    "    knn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=10, \n",
    "    scoring=\"balanced_accuracy\"\n",
    ")\n",
    "\n",
    "mean_cv_list_knn_euclid = np.mean(cv_list_knn_euclid)\n",
    "std_cv_list_knn_euclid = np.std(cv_list_knn_euclid)\n",
    "\n",
    "print(f\"Performance (bac): {round(mean_cv_list_knn_euclid,4)} +- {round(std_cv_list_knn_euclid,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "F3hQoC_e8S7a"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "F_9FJ_Qa3EuV"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PwpHBM1O5SPU"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_hayVU6E6Vwa"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD1Qsbt8d3VN"
   },
   "source": [
    "## Avaliação Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "04m6J0Ik7I0O"
   },
   "outputs": [],
   "source": [
    "# resultados da cross-validacao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Zihz06QXGL5s"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OcwnFU2jITF8"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dlLFP54VMme3"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnBTMOvdNzhG"
   },
   "source": [
    "## Vamos avaliar a performance final do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Tm8433PPLXBP"
   },
   "outputs": [],
   "source": [
    "# retreinar o pipeline selecionado com todos os dados de treinamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "G0BW5wyG-58r"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "CNUu_qpM_-hn"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fI2rqDRgD50s"
   },
   "source": [
    "## Referências & Links\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3Gx27YFEo6c"
   },
   "source": [
    "1. [The Cancer Genome Atlas Program](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga)\n",
    "2. [Micro RNA](https://en.wikipedia.org/wiki/MicroRNA_sequencing)\n",
    "3. [Sklearn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
